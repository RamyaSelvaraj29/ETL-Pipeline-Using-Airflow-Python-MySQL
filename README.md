# ETL-Pipeline-Using-Airflow-Python-MySQL

## Overview 
Modern data platforms handle massive and continuously growing volumes of transactional data that arrive in diverse formats. Ensuring that this raw data is reliably ingested, validated, and transformed into analytics-ready models is essential for accurate reporting and scalable insights.

This project implements an end-to-end ETL pipeline using Apache Airflow, Python, and MySQL, designed to automate data ingestion, validation, transformation, and load. The pipeline standardizes multiple raw CSV inputs into a structured warehouse layer and produces a final analytics-ready table for downstream dashboards and analysis. It demonstrates a scalable, maintainable, and fully automated data workflow that improves data reliability, reduces manual intervention, and supports business intelligence and machine-learning use cases.

## Technology Stack 
- **Orchestration:** ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white)
- **Database:** ![MySQL](https://img.shields.io/badge/MySQL-4479A1?style=flat&logo=mysql&logoColor=white) ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)
- **Containerization:** ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)
- **Data Processing/Transformation:** (https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) (https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
